{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hs1MxbKqZv0w"
      },
      "source": [
        "I'm submitting the task with a week delay, using 8-15 delay days"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehGb6fguZx7b"
      },
      "source": [
        "Video - https://drive.google.com/file/d/1z2eFzAYxQ8023_uIlsMpTr_qrUauTIGl/view?usp=share_link\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "eBY838FrtxRM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import math\n",
        "from matplotlib import pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "RfCw0aRCto1g"
      },
      "outputs": [],
      "source": [
        "def my_sampler(size,dist,requires_grad=False):\n",
        "  dist = torch.tensor(dist)\n",
        "  # Validate dist input - sum of all probs is 1 and all of them are posiive \n",
        "  assert (dist.sum() == 1.0 and dist.all()), f\"dist is invalid array, sum != 1 or not positive, dist: {dist}\"\n",
        "\n",
        "  # Get cumulative sum of dist, in otder to compare to sigma of all the values without calcualting it for every value \n",
        "  dist = dist.cumsum(dim=0)\n",
        "\n",
        "  U = torch.rand(size)\n",
        "\n",
        "  # Default values are I=0, will remain for U < p_0\n",
        "  result = torch.zeros(size, requires_grad = False, dtype=torch.double)\n",
        "\n",
        "  # Second option, if U >= sigma(dist from 0 to n-1) I=n\n",
        "  result = torch.where(U >= torch.sum(dist[:-1]), float(dist.numel() - 1), result)\n",
        "\n",
        "  for i in range(len(dist)-1):\n",
        "\n",
        "    # Find midle value which fills the terms \n",
        "    middle_value = torch.logical_and(dist[i - 1] <= U, U < dist[i])\n",
        "    result = torch.where(middle_value, float(i), result)\n",
        "\n",
        "\n",
        "  result.requires_grad = requires_grad\n",
        "  return result, U\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "6cqC4QBLF0qx"
      },
      "outputs": [],
      "source": [
        "def validate_sample(result, U, dist):\n",
        "  print(\"Validating sample\")\n",
        "  print(\"U\", U)\n",
        "  print(\"result\", result) \n",
        "  dist = torch.tensor(dist)\n",
        "  dist = dist.cumsum(dim=0)\n",
        "\n",
        "  for r,u in zip(result, U):\n",
        "    r_value = int(r.item())\n",
        "    u_value = u.item()\n",
        "    print(r_value,r, u_value, u)\n",
        "    \n",
        "    if r_value == 0:\n",
        "      assert u < dist[0], f\"Wrong 0, r: {r}, u: {u}, dist[0]: {dist[0]}\"\n",
        "    elif r_value == (dist.numel() - 1):\n",
        "      assert u >= torch.sum(dist[:-1]), f\"Wrong 0, r: {r}, u: {u}, dist[0]: {dist[0]}\"\n",
        "    else:\n",
        "      assert torch.logical_and(dist[r_value - 1] <= u, u < dist[r_value]), f\"Wrong value, r: {r}, u: {u}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "SU-UwCL5P_86",
        "outputId": "d9643535-80a9-4490-fe41-af6adc2cd968"
      },
      "outputs": [
        {
          "ename": "AssertionError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-ff7f00f8facc>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# sum(dist) > 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_sampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-73-72e1b53840b4>\u001b[0m in \u001b[0;36mmy_sampler\u001b[0;34m(size, dist, requires_grad)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;31m# Validate dist input - sum of all probs is 1 and all of them are posiive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"dist is invalid array, sum != 1 or not positive, dist: {dist}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;31m# Get cumulative sum of dist, in otder to compare to sigma of all the values without calcualting it for every value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: dist is invalid array, sum != 1 or not positive, dist: tensor([0.1000, 0.2000, 0.6000])"
          ]
        }
      ],
      "source": [
        "# sum(dist) > 1\n",
        "result, U = my_sampler(10,[0.1,0.2, 0.6])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "lzm8EwgLH69_",
        "outputId": "17dce974-c43d-4a35-9c1d-7c9dd570b5dc"
      },
      "outputs": [
        {
          "ename": "AssertionError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-b681bdd7e88e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 0 value in dist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_sampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-73-72e1b53840b4>\u001b[0m in \u001b[0;36mmy_sampler\u001b[0;34m(size, dist, requires_grad)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;31m# Validate dist input - sum of all probs is 1 and all of them are posiive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"dist is invalid array, sum != 1 or not positive, dist: {dist}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;31m# Get cumulative sum of dist, in otder to compare to sigma of all the values without calcualting it for every value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: dist is invalid array, sum != 1 or not positive, dist: tensor([0.0000, 0.2000, 0.6000])"
          ]
        }
      ],
      "source": [
        "# 0 value in dist\n",
        "result, U = my_sampler(10,[0.0,0.2, 0.6])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "8R_Ae3D2yElL",
        "outputId": "1eff244e-59f7-43f8-a36f-254a5988dd35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validating sample\n",
            "U tensor([0.4410, 0.0018, 0.5693, 0.0060, 0.7483, 0.7586, 0.7616, 0.1565, 0.9480,\n",
            "        0.9601])\n",
            "result tensor([2., 0., 2., 0., 2., 2., 2., 1., 2., 2.], dtype=torch.float64)\n",
            "2 tensor(2., dtype=torch.float64) 0.44095003604888916 tensor(0.4410)\n",
            "0 tensor(0., dtype=torch.float64) 0.001841723918914795 tensor(0.0018)\n",
            "2 tensor(2., dtype=torch.float64) 0.5692919492721558 tensor(0.5693)\n",
            "0 tensor(0., dtype=torch.float64) 0.005965173244476318 tensor(0.0060)\n",
            "2 tensor(2., dtype=torch.float64) 0.7483227849006653 tensor(0.7483)\n",
            "2 tensor(2., dtype=torch.float64) 0.7586255669593811 tensor(0.7586)\n",
            "2 tensor(2., dtype=torch.float64) 0.7616266012191772 tensor(0.7616)\n",
            "1 tensor(1., dtype=torch.float64) 0.15653550624847412 tensor(0.1565)\n",
            "2 tensor(2., dtype=torch.float64) 0.9480065107345581 tensor(0.9480)\n",
            "2 tensor(2., dtype=torch.float64) 0.9601357579231262 tensor(0.9601)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "result, U = my_sampler(10,[0.1,0.2, 0.7])\n",
        "validate_sample(result, U, [0.1,0.2, 0.7])\n",
        "\n",
        "result = result.detach().numpy()\n",
        "plt.hist(result)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "sN_7wSz76mwG"
      },
      "outputs": [],
      "source": [
        "class MyScalar:\n",
        "    def __init__(self, value, gradient = torch.tensor(0), parent = None):\n",
        "      self.value = value\n",
        "      self.gradient = gradient\n",
        "      self.parent = parent\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"value: {self.value}, gradient: {self.gradient}, parent: {self.parent}\"\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"value: {self.value}, gradient: {self.gradient}, parent: {self.parent}\"\n",
        "\n",
        "def add(current, other):\n",
        "  # Derivative is 1\n",
        "  return MyScalar(current.value + other, torch.tensor(1), current)\n",
        "  \n",
        "def mul(current, other):\n",
        "    # Derivative is other\n",
        "    return MyScalar(current.value * other, torch.tensor(other), current)\n",
        "\n",
        "\n",
        "def pow(current, other):\n",
        "    # Derivative is other * (value ^ (other-1))\n",
        "    return MyScalar(current.value ** other, other *  (current.value ** (other -1)), current)\n",
        "\n",
        "def exp(current):\n",
        "    # Derivative is e ^ value\n",
        "    return MyScalar(torch.exp(torch.tensor(current.value)), torch.exp(torch.tensor(current.value)), current)\n",
        "\n",
        "def ln(current):\n",
        "    # Derivative is 1/value\n",
        "    return MyScalar(torch.log(torch.tensor(current.value)), 1/current.value, current)    \n",
        "\n",
        "def sin(current):\n",
        "    # Derivative is cos(value)\n",
        "    return MyScalar(torch.sin(torch.tensor(current.value)), torch.cos(torch.tensor(current.value)), current)\n",
        "\n",
        "def cos(current):\n",
        "    # Derivative is sin(value)\n",
        "    return MyScalar(torch.cos(torch.tensor(current.value)), -torch.sin(torch.tensor(current.value)), current)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "j85dvGS-yi7C"
      },
      "outputs": [],
      "source": [
        "def get_gradient_recursive(MyScalar_Input, results, partial_grad):\n",
        "  results[MyScalar_Input] = partial_grad\n",
        "\n",
        "  if MyScalar_Input.parent is None:\n",
        "    return partial_grad\n",
        "  \n",
        "  return get_gradient_recursive(MyScalar_Input.parent, results, partial_grad * MyScalar_Input.gradient)\n",
        "\n",
        "def get_gradient(MyScalar_Input):\n",
        "   results = dict()\n",
        "   partial_grad = get_gradient_recursive(MyScalar_Input, results, torch.tensor(1))\n",
        "\n",
        "   return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmGap7AqfqV5",
        "outputId": "198b23fe-337c-4a91-b717-5493e7d5eaf6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "My gradient system:  dict_values([tensor(1), tensor(1.0405), tensor(-0.4148), tensor(-0.5063), tensor(-0.2903), tensor(-0.0811), tensor(-0.1622), tensor(-0.1622)])\n",
            "Torch gradient system:  tensor([-0.1622])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-87-cbb726029edd>:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return MyScalar(torch.sin(torch.tensor(current.value)), torch.cos(torch.tensor(current.value)), current)\n",
            "<ipython-input-87-cbb726029edd>:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return MyScalar(torch.log(torch.tensor(current.value)), 1/current.value, current)\n",
            "<ipython-input-87-cbb726029edd>:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return MyScalar(torch.exp(torch.tensor(current.value)), torch.exp(torch.tensor(current.value)), current)\n"
          ]
        }
      ],
      "source": [
        "# My gradient system\n",
        "a=MyScalar(2)\n",
        "b = add(a, 1)\n",
        "c = mul(b, 2)\n",
        "d = cos(c)\n",
        "e = sin(d)\n",
        "f = ln(e)\n",
        "g=pow(f,2)\n",
        "h=exp(g)\n",
        "i=get_gradient(h)\n",
        "\n",
        "# Pytorch gradient system\n",
        "a_torch_grad = torch.tensor([2.], requires_grad=True)\n",
        "b_torch_grad  = torch.add(a_torch_grad, 1)\n",
        "c_torch_grad  = torch.mul(b_torch_grad, 2)\n",
        "d_torch_grad  = torch.cos(c_torch_grad)\n",
        "e_torch_grad  = torch.sin(d_torch_grad)\n",
        "f_torch_grad  = torch.log(e_torch_grad)\n",
        "g_torch_grad  = torch.pow(f_torch_grad, 2)\n",
        "h_torch_grad  = torch.exp(g_torch_grad)\n",
        "\n",
        "h_torch_grad.backward()\n",
        "\n",
        "print(\"My gradient system: \", i.values())\n",
        "print(\"Torch gradient system: \", a_torch_grad.grad)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
